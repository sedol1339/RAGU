{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0322898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "\n",
    "from ragu.llm.llm import CachedOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e552e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragu.common.logger import logger\n",
    "logger.add(sys.stderr, level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d30abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CachedOpenAI(\n",
    "    base_url=os.environ['VSEGPT_BASE_URL'],\n",
    "    api_key=os.environ['VSEGPT_KEY'],\n",
    "    cache='cache_dir/',\n",
    "    rate_min_delay=1,\n",
    "    retry_times_sec=(1, 2, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecfb5ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"Sure! What information would you like me to fill in?\",\n",
      "  \"time\": \"2023-10-31T12:00:00Z\",\n",
      "  \"jokes\": [\n",
      "    \"Why did the scarecrow win an award? Because he was outstanding in his field!\",\n",
      "    \"What do you call fake spaghetti? An impasta!\",\n",
      "    \"Why donâ€™t scientists trust atoms? Because they make up everything!\"\n",
      "  ],\n",
      "  \"chipi_chipi_chapa_chapa\": [\n",
      "    \"Chipi chipi, now let's get started!\",\n",
      "    \"Chapa chapa, are you ready for some fun?\",\n",
      "    \"Chipi chipi, here comes the excitement!\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Response(BaseModel):\n",
    "    answer: str\n",
    "    time: str\n",
    "    jokes: list[str]\n",
    "    chipi_chipi_chapa_chapa: list[str]\n",
    "\n",
    "answer = await llm.chat_completion(\n",
    "    'openai/gpt-3.5-turbo',\n",
    "    [{'role': 'user', 'content': 'Hi! Fill the fields!'}],\n",
    "    output_schema=Response\n",
    ")\n",
    "print(answer.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212f50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00958252  0.01318359  0.01171875 ...  0.00283813  0.00524902\n",
      "  -0.00170135]\n",
      " [ 0.00830078  0.01177979  0.01507568 ...  0.00154877  0.00328064\n",
      "   0.00017452]\n",
      " [ 0.01306152  0.0123291   0.01495361 ...  0.00396729  0.00613403\n",
      "  -0.00294495]]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "embeddings = await asyncio.gather(*[\n",
    "    llm.embed_text('emb-qwen/qwen3-embedding-8b', f'Pepe watafa{i}')\n",
    "    for i in range(3)\n",
    "])\n",
    "print(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0af870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-ragu (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
