{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97727bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "from ragu import (\n",
    "    SimpleChunker,\n",
    "    KnowledgeGraph,\n",
    "    BuilderArguments,\n",
    "    Settings,\n",
    "    ArtifactsExtractorLLM,\n",
    ")\n",
    "from ragu.chunker.chunkers import SemanticTextChunker\n",
    "from ragu.llm import OpenAIClient\n",
    "from ragu.embedder import OpenAIEmbedder\n",
    "\n",
    "from ragu.utils.ragu_utils import read_text_from_files\n",
    "\n",
    "# Configuration (or use ragu.Env for loading from .env)\n",
    "LLM_MODEL_NAME = \"qwen/qwen3-14b\"\n",
    "LLM_BASE_URL = os.environ['VSEGPT_BASE_URL']\n",
    "LLM_API_KEY = os.environ['VSEGPT_KEY']\n",
    "\n",
    "EMBEDDER_MODEL_NAME = \"emb-qwen/qwen3-embedding-8b\"  # https://vsegpt.ru/Docs/Models/Embeddings\n",
    "\n",
    "# Set up LLM client\n",
    "client = OpenAIClient(\n",
    "    model_name=LLM_MODEL_NAME,\n",
    "    base_url=LLM_BASE_URL,\n",
    "    api_token=LLM_API_KEY,\n",
    "    max_requests_per_second=1,\n",
    "    max_requests_per_minute=60,\n",
    "    cache_flush_every=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768706d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure working directory and language\n",
    "Settings.storage_folder = \"bl_index\"\n",
    "Settings.language = \"english\"  # or \"russian\"\n",
    "\n",
    "# Load documents from folder\n",
    "docs = read_text_from_files(\"/home/oleg/rag_workspace/natural_rag/datasets/bl_small/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c17705",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = SemanticTextChunker('all-mpnet-base-v2', max_chunk_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ceddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_extractor = ArtifactsExtractorLLM(\n",
    "    client=client,\n",
    "    do_validation=False\n",
    ")\n",
    "\n",
    "embedder = OpenAIEmbedder(\n",
    "    model_name=EMBEDDER_MODEL_NAME,\n",
    "    base_url=LLM_BASE_URL,\n",
    "    api_token=LLM_API_KEY,\n",
    "    dim=4096,\n",
    "    max_requests_per_second=1,\n",
    "    max_requests_per_minute=60,\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "builder_settings = BuilderArguments(\n",
    "    use_llm_summarization=True,\n",
    "    vectorize_chunks=True,\n",
    ")\n",
    "\n",
    "knowledge_graph = KnowledgeGraph(\n",
    "    client=client,\n",
    "    embedder=embedder,\n",
    "    chunker=chunker,\n",
    "    artifact_extractor=artifact_extractor,\n",
    "    builder_settings=builder_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607157d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph = await knowledge_graph.build_from_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, MutableMapping\n",
    "from diskcache import Index\n",
    "\n",
    "shelf: MutableMapping[str, Any] = Index('database/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a171a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph = await knowledge_graph.build_from_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a55b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragu import LocalSearchEngine\n",
    "\n",
    "local_search = LocalSearchEngine(\n",
    "    client,\n",
    "    knowledge_graph,\n",
    "    embedder,\n",
    "    tokenizer_model=\"gpt-4o-mini\",\n",
    ")\n",
    "query = '''\\\n",
    "<конец секции документов>\n",
    "Как попас\n",
    "'''\n",
    "print(query)\n",
    "context = await local_search.a_search(query, top_k=20)\n",
    "answer = await local_search.a_query(quert, top_k=20)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9434fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-ragu (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
